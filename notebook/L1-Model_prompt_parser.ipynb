{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "073bf8f9",
   "metadata": {},
   "source": [
    "# LangChain: 模型, 提示词以及数据解析\n",
    "\n",
    "![overview](../docs/l1/overview.jpeg)\n",
    "\n",
    "> 注:\n",
    ">\n",
    "> 1.  本文是基于吴恩达《[LangChain for LLM Application Development](https://learn.deeplearning.ai/langchain/lesson/1/introduction)》课程的学习笔记；\n",
    "> 2.  完整的课程内容以及示例代码/Jupyter笔记见：[LangChain-for-LLM-Application-Development](https://github.com/madroidmaq/LangChain-for-LLM-Application-Development)；\n",
    "\n",
    "## 课程大纲\n",
    "\n",
    "此主要包括两部：\n",
    "1. 直接使用 OpenAI API 接口进行调用，直观感受下其 API 的使用方式以及存在的问题；\n",
    "2. 使用 LangChain 的 API 对上述问题进行优化，主要包括 3 个方面：\n",
    "   1. Prompts：提示词，期望语言模型返回的内容。也就是我们通常理解的问题；\n",
    "   2. Models：模型，是指支撑大部分工作的语言模型；\n",
    "   3. Output parsers:返回数据解析，是指将语言模型的返回的结构化信息（JSON）进一步处理分发；\n",
    "\n",
    "\n",
    "其中 LangChain 部分的主要内容如下图：\n",
    "\n",
    "![whiteboard_exported_image](../docs/l1/langchain_flow.png)\n",
    "\n",
    "\n",
    "直接使用 OpenAI API 完成一个 LLM 应用的开发，会存在很多的胶水代码，而 LangChain 就是提供的一种很好的方式来处理上述的一些问题。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a01ff606",
   "metadata": {},
   "source": [
    "## 获取 OpenAI API Key\n",
    "\n",
    "在开始之前请确保你已经有 [OpenAI API Key](https://platform.openai.com/account/api-keys) 了，这个是访问 OpenAI API 接口的凭证，也是通过这个 Key 来进行计费的。\n",
    "\n",
    "将 API Key 设置到系统的环境变量之后，就可以安装 OpenAI 提供的 Python SDK 了。通过 `os.environ['OPENAI_API_KEY']` 获取系统遍历中设置的 key，让后将其设置到 SDK 中。\n",
    "\n",
    "> 注：这里是最佳实践，这种方式可以在多个项目中使用相同的 key，同时不用将 key 记录到版本控制中。当然，你也可以直接将 key 写死在代码中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70aa2619",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-02T06:18:27.423644Z",
     "start_time": "2023-06-02T06:18:27.349719Z"
    }
   },
   "outputs": [],
   "source": [
    "# 安装对应的依赖\n",
    "%pip install python-dotenv\n",
    "%pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7ed03ed-1322-49e3-b2a2-33e94fb592ef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-02T06:35:22.708283Z",
     "start_time": "2023-06-02T06:35:22.699255Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "\n",
    "# 设置 API Key\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "openai.api_key = os.environ['OPENAI_API_KEY']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bbad9cdb",
   "metadata": {},
   "source": [
    "## OpenAI : Chat API \n",
    "\n",
    "下面我们就开始看一下 OpenAI 对话的接口是如何使用的。首先定义一个对话函数 `get_completion()`，然后使用这个函数开始一个简单的对话。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "484bfa6a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-02T06:18:27.450690Z",
     "start_time": "2023-06-02T06:18:27.362512Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 定义函数，封装 OpenAI SDK 的一些基本参数\n",
    "def get_completion(prompt, model=\"gpt-3.5-turbo\"):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0, \n",
    "    )\n",
    "    return response.choices[0].message[\"content\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a1d076ce",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-06-02T06:18:27.367046Z"
    },
    "is_executing": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'As an AI language model, I can tell you that the answer to 1+1 is 2.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 询问问题：What is 1+1?\n",
    "get_completion(\"What is 1+1?\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "da2651e7",
   "metadata": {},
   "source": [
    "### 复杂 Prompt\n",
    "\n",
    "上面 1+1 等于几的问题非常简单，在正式的项目开发中使用场景往往会更加复杂。我们以收到用户反馈邮件场景为例看一下 OpenAI 的 SDK 应该如何使用。\n",
    "\n",
    "场景是你在一个国际化的公司，经常会收到一些不同国家用户的邮件反馈，同时用户遇到问题时情绪可能是比较激烈的。所以我们的 Prompt 需要做两件事情：\n",
    "1. 将不同的语种翻译成中文，方便阅读；\n",
    "2. 将邮件中的语气进行调整， 使其更加平静友好（这样容易开展工作😜）；\n",
    "\n",
    "我们编写的 Prompt 中首先会有用户的邮件内容，同时为了扩展性我们把邮件的语气也提取出来，方便将内容根据不同的场景扩展成不同的风格。\n",
    "\n",
    "下面是一些具体的代码细节：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b32b57a",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-06-02T06:18:32.536592Z"
    },
    "is_executing": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translate the text that is delimited by triple backticks \n",
      "into a style that is American English in a calm friendly formal and respectful tone , at last translate to Simplified Chinese.\n",
      "text: ```\n",
      "Arrr, I be fuming that me blender lid flew off and splattered me kitchen walls with smoothie! And to make matters worse,the warranty don't cover the cost of cleaning up me kitchen. I need yer help right now, matey!\n",
      "```\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 用户的原始邮件内容\n",
    "customer_email = \"\"\"\n",
    "Arrr, I be fuming that me blender lid \\\n",
    "flew off and splattered me kitchen walls \\\n",
    "with smoothie! And to make matters worse,\\\n",
    "the warranty don't cover the cost of \\\n",
    "cleaning up me kitchen. I need yer help \\\n",
    "right now, matey!\n",
    "\"\"\"\n",
    "\n",
    "# 转录邮件的语气风格\n",
    "style = \"\"\"American English in a calm friendly formal and respectful tone , at last translate to Simplified Chinese\"\"\"\n",
    "\n",
    "prompt = f\"\"\"Translate the text \\\n",
    "that is delimited by triple backticks \n",
    "into a style that is {style}.\n",
    "text: ```{customer_email}```\n",
    "\"\"\"\n",
    "\n",
    "# 打印完整的提示词\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c883dcbd",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-06-02T06:18:32.573287Z"
    },
    "is_executing": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ahoy there, I am quite upset that my blender lid flew off and made a mess of my kitchen walls with smoothie! To add to my frustration, the warranty does not cover the cost of cleaning up my kitchen. I would greatly appreciate your assistance at this time, my friend. \n",
      "\n",
      "嗨，我非常生气，因为我的搅拌机盖子飞了出去，把我的厨房墙壁弄得到处都是果汁！更糟糕的是，保修不包括清理厨房的费用。朋友，我现在需要你的帮助。\n"
     ]
    }
   ],
   "source": [
    "# 请求接口，并查看返回内容\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f80482d1",
   "metadata": {},
   "source": [
    "## LangChain : 对话 API\n",
    "\n",
    "上面是使用 OpenAI 原始的 SDK 完成上述任务需要将不同信息以及不同的指令组装真一个完整的 Prompt，然后将其传递给模型。如果我们需要的封装的信息很多，上述拼接的过程将会变得繁琐，并且会成为胶水代码。另外就是，Prompt 的构建必须在所有的信息都准备完成之后，才能定义 Prompt 的字段。\n",
    "\n",
    "下面我们就看一下使用 LangChain 怎么完成上述的任务。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a525b58",
   "metadata": {
    "is_executing": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 下载 langchain 依赖\n",
    "# langchain 版本迭代速度很快，目前示例代码是基于 0.0.188 版本开发，其他版本可能会导致一些代码无法运行。\n",
    "%pip install --upgrade langchain==0.0.188"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a25c5b27",
   "metadata": {},
   "source": [
    "### 模型：Model\n",
    "\n",
    "这里的模型指的就是大语言模型（LLM），可以根据输入的 Prompt 进行推理，并给出对应的结果。LangChain 封装多个 LLM 的实现， OpenAI 就是其中的一个。下面看一下如何通过 LangChain 来访问 OpenAI 的功能，封装的模型为 `ChatOpenAI` ，使用前需要先导包。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1cc0c8b8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-02T06:18:32.601045Z",
     "start_time": "2023-06-02T06:18:32.550306Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "verbose=False callbacks=None callback_manager=None client=<class 'openai.api_resources.chat_completion.ChatCompletion'> model_name='gpt-3.5-turbo' temperature=0.0 model_kwargs={} openai_api_key=None openai_api_base=None openai_organization=None openai_proxy=None request_timeout=None max_retries=6 streaming=False n=1 max_tokens=None\n"
     ]
    }
   ],
   "source": [
    "# 导包 ChatOpenAI\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "# 有很多参数（是gpt-3.5还是gpt-4等等）可以设置，这里以 temperature 参数为例\n",
    "chat = ChatOpenAI(temperature=0.0)\n",
    "print(chat)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b4d07256",
   "metadata": {},
   "source": [
    "### 提示词模版：Prompt template\n",
    "\n",
    "#### 翻译邮件\n",
    "\n",
    "在 OpenAI 原始接口的部分，我们需要把所有的信息组装成一个最终的 Prompt 进行使用，在 LangChain 中对这部分也进行了封装，是其使用起来更加方便。\n",
    "\n",
    "首先我们定义一个 `template_string` Prompt，其包含两个带输入的信息：style 和 text ，与上面的信息基本一致，然后通过这个字符串可以构建出一个 `PromptTemplate` 类，我们可以通过这个类可以做到一些更灵活的事情，代码大致如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3a31f246",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-02T06:18:38.321942Z",
     "start_time": "2023-06-02T06:18:38.307470Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['style', 'text'] output_parser=None partial_variables={} template='Translate the text that is delimited by triple backticks into a style that is {style}. text: ```{text}```\\n' template_format='f-string' validate_template=True\n",
      "['style', 'text']\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import ChatPromptTemplate, HumanMessagePromptTemplate\n",
    "\n",
    "# 定义 Prompt\n",
    "template_string = \"\"\"Translate the text \\\n",
    "that is delimited by triple backticks \\\n",
    "into a style that is {style}. \\\n",
    "text: ```{text}```\n",
    "\"\"\"\n",
    "\n",
    "# 备注：应该是视频中使用的 LangChain 版本与我本地使用的版本（0.0.188）不同，导致 API 报错\n",
    "# 已使用 HumanMessagePromptTemplate 替换 ChatPromptTemplate 的部分用法；\n",
    "# 原始写法如下：\n",
    "# prompt_template = ChatPromptTemplate.from_messages(template_string)\n",
    "\n",
    "human_prompt_template = HumanMessagePromptTemplate.from_template(template_string)\n",
    "prompt_template = ChatPromptTemplate.from_messages([human_prompt_template])\n",
    "\n",
    "# 打印构建出的 Prompt 的完整内容\n",
    "prompt = prompt_template.messages[0].prompt\n",
    "print(prompt)\n",
    "\n",
    "# 打印构建出的 Prompt 包含需要替换的属性\n",
    "print(prompt.input_variables)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bc9e154d",
   "metadata": {},
   "source": [
    "好的，下面我们补全缺少的 style 和 text 信息，并通过 ChatPromptTemplate 中的 format_messages 函数将其传入，大致代码如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bbd51a93",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\"Translate the text that is delimited by triple backticks into a style that is American English in a calm friendly formal and respectful tone , at last translate to Simplified Chinese. text: ```\\nArrr, I be fuming that me blender lid flew off and splattered me kitchen walls with smoothie! And to make matters worse, the warranty don't cover the cost of cleaning up me kitchen. I need yer help right now, matey!\\n```\\n\" additional_kwargs={} example=False\n"
     ]
    }
   ],
   "source": [
    "# style\n",
    "customer_style = \"American English in a calm friendly formal and respectful tone , at last translate to Simplified Chinese\"\n",
    "# text\n",
    "customer_email = \"\"\"\n",
    "Arrr, I be fuming that me blender lid \\\n",
    "flew off and splattered me kitchen walls \\\n",
    "with smoothie! And to make matters worse, \\\n",
    "the warranty don't cover the cost of \\\n",
    "cleaning up me kitchen. I need yer help \\\n",
    "right now, matey!\n",
    "\"\"\"\n",
    "\n",
    "# 传入对应的 style 和 text 信息\n",
    "customer_messages = prompt_template.format_messages(\n",
    "                    style=customer_style,\n",
    "                    text=customer_email)\n",
    "# 查看输出\n",
    "print(customer_messages[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "08f57a96",
   "metadata": {},
   "source": [
    "根据输出可以看出，上面缺少的信息已经补充完整，customer_messages 已经是一个完整的 Prompt 了。下面把这个完整的 Prompt 输入到 ChatOpenAI 中，查看其返回情况："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bd789f9f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am quite upset that my blender lid flew off and splattered my kitchen walls with smoothie! To make matters worse, the warranty does not cover the cost of cleaning up my kitchen. I would greatly appreciate your assistance at this time, my friend.\n",
      "\n",
      "我很生气，我的搅拌机盖子飞了出去，把我的厨房墙壁都弄脏了！更糟糕的是，保修不包括清洁我的厨房的费用。我的朋友，我现在需要你的帮助。\n"
     ]
    }
   ],
   "source": [
    "# Call the LLM to translate to the style of the customer message\n",
    "customer_response = chat(customer_messages)\n",
    "print(customer_response.content)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "635c0402",
   "metadata": {},
   "source": [
    "#### 回复邮件\n",
    "\n",
    "上述使用 LangChain 完成翻译润色客户邮件的场景，下面我们就看一下如何使用同样的方式来回复用户的邮件。\n",
    "\n",
    "我们使用中文编写对应的回复邮件，需要将其翻译成目标语言（这里是英文）并且需要去除一些口语化的表达，下面是回复的内容以及对应的 Prompt。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2ff72bd1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translate the text that is delimited by triple backticks into a style that is a polite tone that speaks in English Pirate. text: ```额，保修不包括你的厨房的清洁费用，\n",
      "因为你使用搅拌机的时候忘记盖上盖子了，这是你操作的失误，这是你的问题。真倒霉！再见！\n",
      "```\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 回复内容\n",
    "service_reply = \"\"\"额，保修不包括你的厨房的清洁费用，\n",
    "因为你使用搅拌机的时候忘记盖上盖子了，这是你操作的失误，这是你的问题。真倒霉！再见！\n",
    "\"\"\"\n",
    "\n",
    "# 要求\n",
    "service_style_pirate = \"\"\"\\\n",
    "a polite tone \\\n",
    "that speaks in English Pirate\\\n",
    "\"\"\"\n",
    "\n",
    "# 组装 prompt\n",
    "service_messages = prompt_template.format_messages(\n",
    "    style=service_style_pirate,\n",
    "    text=service_reply)\n",
    "\n",
    "# 打印&检查 prompt\n",
    "print(service_messages[0].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a0ae5552",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arrr, me hearty! Beggin' yer pardon, but the warranty don't be coverin' the cost o' cleanin' yer galley, as ye forgot to put the lid on yer blender, which be a mistake on yer part. 'Tis yer own problem, matey. Aye, tough luck! Farewell!\n"
     ]
    }
   ],
   "source": [
    "# 生成对应的回复邮件文本\n",
    "service_response = chat(service_messages)\n",
    "print(service_response.content)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c33d2fb1",
   "metadata": {},
   "source": [
    "### prompt template 的优势\n",
    "\n",
    "可以看出 prompt_template 是对我们自己的 Prompt 做了一层封装，是其使用起来比较方便，在复杂应用开发时也可以很好的复用这些逻辑。\n",
    "\n",
    "除此之外，LangChain 中的 prompt template 还提供了一些其他的功能：\n",
    "1. 内置了多种 Prompt（如文本总结/QA/SQL/API调用等），不用我们自己再调试最佳的 Prompt；\n",
    "2. 支持输出解析（Output Parsers），将 LLM 的结果以结构化（如 JSON）的方式返回；\n",
    "3. 内置了思维链，使 LLM 的回答更加合理；\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "36536e79",
   "metadata": {},
   "source": [
    "## 输出解析器：Output Parsers\n",
    "\n",
    "下面我们介绍下输出解析（Output Parsers）的使用场景。假如我们现在有到一些商品的评价，想要对这些评价做一些处理从而可以更好的分析数据。比如，我们期望可以根据输入用户的商品评价，输出对应的 JOSN 数据，包含以下字段信息：\n",
    "- gift：是否是把商品当作礼物， bool 类型；\n",
    "- delivery_days：商品配送时间，没有的话返回 -1 ；\n",
    "- price_value：提起有关价格相关的信息，返回一个列表；\n",
    "\n",
    "\n",
    "我们期望 LLM 返回下面的 JSON 格式："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ccdff5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gift': False, 'delivery_days': 5, 'price_value': 'pretty affordable!'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{\n",
    "  \"gift\": False,\n",
    "  \"delivery_days\": 5,\n",
    "  \"price_value\": \"pretty affordable!\"\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bc041643",
   "metadata": {},
   "source": [
    "下面是从京东上随机挑选的一个 MacBook Pro 的评价，以及对应的 Prompt 信息。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df0f4680",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 用户的商品评价\n",
    "customer_review = \"\"\"\n",
    "MacBook Pro特别棒！特别喜欢！m2处理器性能超强，就是价钱有点小贵！电池续航逆天！不发热！还带有黑科技触控栏！\n",
    "现在Mac 软件还算蛮多的，常用的办公软件都能有！用来日常办公完全没问题！\n",
    "我想重点点评一下他的音频接口！这代MacBook Pro 带有先进的高阻抗耳机支持功能！同样的耳机，\n",
    "插MacBook Pro上，效果要好于iPhone！还有它的录音性能！插上一根简单的转接头后，在配合电容麦，\n",
    "还有库乐队软件，录音效果逆天！真的特别棒！我有比较老版本的Mac，但这代MacBook Pro的录音效果，\n",
    "真的比以前的Mac效果要好好多倍！特别逆天！适合音乐人！（个人感觉，不插电源，录音效果似乎会更好！）\n",
    "\"\"\"\n",
    "\n",
    "# Prompt 编写\n",
    "review_template = \"\"\"\\\n",
    "For the following text, extract the following information:\n",
    "\n",
    "gift: Was the item purchased as a gift for someone else? \\\n",
    "Answer True if yes, False if not or unknown.\n",
    "\n",
    "delivery_days: How many days did it take for the product \\\n",
    "to arrive? If this information is not found, output -1.\n",
    "\n",
    "price_value: Extract any sentences about the value or price,\\\n",
    "and output them as a comma separated Python list.\n",
    "\n",
    "Format the output as JSON with the following keys:\n",
    "gift\n",
    "delivery_days\n",
    "price_value\n",
    "\n",
    "text: {text}\n",
    "\"\"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d7a06569",
   "metadata": {},
   "source": [
    "下面是具体的请求逻辑："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121bb0d4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HumanMessage(content='For the following text, extract the following information:\\n\\ngift: Was the item purchased as a gift for someone else? Answer True if yes, False if not or unknown.\\n\\ndelivery_days: How many days did it take for the product to arrive? If this information is not found, output -1.\\n\\nprice_value: Extract any sentences about the value or price,and output them as a comma separated Python list.\\n\\nFormat the output as JSON with the following keys:\\ngift\\ndelivery_days\\nprice_value\\n\\ntext: \\nMacBook Pro特别棒！特别喜欢！m2处理器性能超强，就是价钱有点小贵！电池续航逆天！不发热！还带有黑科技触控栏！\\n现在Mac 软件还算蛮多的，常用的办公软件都能有！用来日常办公完全没问题！\\n我想重点点评一下他的音频接口！这代MacBook Pro 带有先进的高阻抗耳机支持功能！同样的耳机，\\n插MacBook Pro上，效果要好于iPhone！还有它的录音性能！插上一根简单的转接头后，在配合电容麦，\\n还有库乐队软件，录音效果逆天！真的特别棒！我有比较老版本的Mac，但这代MacBook Pro的录音效果，\\n真的比以前的Mac效果要好好多倍！特别逆天！适合音乐人！（个人感觉，不插电源，录音效果似乎会更好！）\\n\\n', additional_kwargs={}, example=False)]\n",
      "{\n",
      "    \"gift\": false,\n",
      "    \"delivery_days\": -1,\n",
      "    \"price_value\": [\"就是价钱有点小贵！\"]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "# 创建 ChatPromptTemplate\n",
    "prompt_template = ChatPromptTemplate.from_template(review_template)\n",
    "messages = prompt_template.format_messages(text=customer_review)\n",
    "print(messages)\n",
    "\n",
    "# 创建 LLM\n",
    "chat = ChatOpenAI(temperature=0.0)\n",
    "\n",
    "# 请求\n",
    "response = chat(messages)\n",
    "print(response.content)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ccd5a831",
   "metadata": {},
   "source": [
    "可以看出 response 返回结果基本和我们预期的一致，但是这个时候我们并不能直接操纵这个 JOSN，目前他还只是一个字符串，比如下面的代码会报错。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a3c0609",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'get'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[58], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# You will get an error by running this line of code \u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39m# because'gift' is not a dictionary\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39m# 'gift' is a bool\u001b[39;00m\n\u001b[1;32m      4\u001b[0m response\u001b[39m.\u001b[39mcontent\n\u001b[0;32m----> 5\u001b[0m response\u001b[39m.\u001b[39;49mcontent\u001b[39m.\u001b[39;49mget(\u001b[39m'\u001b[39m\u001b[39mgift\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'get'"
     ]
    }
   ],
   "source": [
    "# 下面的代码会报错，因为 content 并不是字典，而是一个字符串\n",
    "response.content.get('gift')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5f7de2b8",
   "metadata": {},
   "source": [
    "### Parse the LLM output string into a Python dictionary\n",
    "\n",
    "解决上面的报错，就需要用到 LangChain 的数据解析功能了。首先我们需要导入 ResponseSchema 和 StructuredOutputParser，代码如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dea24b4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"\\`\\`\\`json\" and \"\\`\\`\\`\":\n",
      "\n",
      "```json\n",
      "{\n",
      "\t\"gift\": string  // Was the item purchased as a gift for someone else? Answer True if yes,False if not or unknown.\n",
      "\t\"delivery_days\": string  // How many days did it take for the product to arrive? If this information is not found, output -1.\n",
      "\t\"price_value\": string  // Extract any sentences about the value or price, and output them as a comma separated Python list.\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "from langchain.output_parsers import ResponseSchema\n",
    "from langchain.output_parsers import StructuredOutputParser\n",
    "\n",
    "# 对每个期望返回的内容做一个详细的描述，确保 LLM 知道你的意图\n",
    "gift_schema = ResponseSchema(name=\"gift\",\n",
    "                             description=\"Was the item purchased as a gift for someone else? Answer True if yes,False if not or unknown.\")\n",
    "delivery_days_schema = ResponseSchema(name=\"delivery_days\",\n",
    "                                      description=\"How many days did it take for the product to arrive? If this information is not found, output -1.\")\n",
    "price_value_schema = ResponseSchema(name=\"price_value\",\n",
    "                                    description=\"Extract any sentences about the value or price, and output them as a comma separated Python list.\")\n",
    "# 以字典的方式构建 schema\n",
    "response_schemas = [gift_schema, \n",
    "                    delivery_days_schema,\n",
    "                    price_value_schema]\n",
    "\n",
    "# 创建 OutputParser\n",
    "output_parser = StructuredOutputParser.from_response_schemas(response_schemas)\n",
    "\n",
    "# 生成对应的指令，这里会做为 Prompt 内容的一部分\n",
    "format_instructions = output_parser.get_format_instructions()\n",
    "print(format_instructions)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6ec882f1",
   "metadata": {},
   "source": [
    "下面就是将 format_instructions 内容与 Prompt 整合在一起了，并且生成最终的 Prompt 信息。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "082947fc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the following text, extract the following information:\n",
      "\n",
      "gift: Was the item purchased as a gift for someone else? Answer True if yes, False if not or unknown.\n",
      "\n",
      "delivery_days: How many days did it take for the productto arrive? If this information is not found, output -1.\n",
      "\n",
      "price_value: Extract any sentences about the value or price,and output them as a comma separated Python list.\n",
      "\n",
      "text: \n",
      "MacBook Pro特别棒！特别喜欢！m2处理器性能超强，就是价钱有点小贵！电池续航逆天！不发热！还带有黑科技触控栏！\n",
      "现在Mac 软件还算蛮多的，常用的办公软件都能有！用来日常办公完全没问题！\n",
      "我想重点点评一下他的音频接口！这代MacBook Pro 带有先进的高阻抗耳机支持功能！同样的耳机，\n",
      "插MacBook Pro上，效果要好于iPhone！还有它的录音性能！插上一根简单的转接头后，在配合电容麦，\n",
      "还有库乐队软件，录音效果逆天！真的特别棒！我有比较老版本的Mac，但这代MacBook Pro的录音效果，\n",
      "真的比以前的Mac效果要好好多倍！特别逆天！适合音乐人！（个人感觉，不插电源，录音效果似乎会更好！）\n",
      "\n",
      "\n",
      "The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"\\`\\`\\`json\" and \"\\`\\`\\`\":\n",
      "\n",
      "```json\n",
      "{\n",
      "\t\"gift\": string  // Was the item purchased as a gift for someone else? Answer True if yes,False if not or unknown.\n",
      "\t\"delivery_days\": string  // How many days did it take for the product to arrive? If this information is not found, output -1.\n",
      "\t\"price_value\": string  // Extract any sentences about the value or price, and output them as a comma separated Python list.\n",
      "}\n",
      "```\n",
      "\n"
     ]
    }
   ],
   "source": [
    "review_template_2 = \"\"\"\\\n",
    "For the following text, extract the following information:\n",
    "\n",
    "gift: Was the item purchased as a gift for someone else? \\\n",
    "Answer True if yes, False if not or unknown.\n",
    "\n",
    "delivery_days: How many days did it take for the product\\\n",
    "to arrive? If this information is not found, output -1.\n",
    "\n",
    "price_value: Extract any sentences about the value or price,\\\n",
    "and output them as a comma separated Python list.\n",
    "\n",
    "text: {text}\n",
    "\n",
    "{format_instructions}\n",
    "\"\"\"\n",
    "\n",
    "human_prompt_template = HumanMessagePromptTemplate.from_template(review_template_2)\n",
    "prompt = ChatPromptTemplate.from_messages([human_prompt_template])\n",
    "\n",
    "messages = prompt.format_messages(text=customer_review, format_instructions=format_instructions)\n",
    "print(messages[0].content)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "746927b0",
   "metadata": {},
   "source": [
    "我们请求 LLM 并查看其返回的信息，"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b663657",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['就是价钱有点小贵！']\n"
     ]
    }
   ],
   "source": [
    "# 请求 LLM\n",
    "response = chat(messages)\n",
    "# 将结果解析成对应的字典\n",
    "output_dict = output_parser.parse(response.content)\n",
    "\n",
    "print(output_dict.get('price_value'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "656b98da",
   "metadata": {},
   "source": [
    "## 小结\n",
    "\n",
    "本节课程带你体验了使用 OpenAI SDK 进行对话的简单，在这个过程中会存在一些胶水代码。这个问题在小项目中并不是什么问题，但是在大型项目中却是不能忽视的工程问题，为了解决上述问题我们引入了 LangChain 这个库，他会把整个对话的流程封装起来，根据容易扩展：\n",
    "1. 在 Prompt 输入方面，除了使用灵活之外还提供了各种场景的最佳 Prompt 写法；\n",
    "2. 在 Model 方面，提供了一些默认的 OpenAI 请求参数，同时如果后期替换成其他的 LLM 模型也会比较方便；\n",
    "3. 在 LLM 数据处理方便，可以使用 Output Parsers 很好的将结果处理成字典格式，方便后续的进一步操作；\n",
    "\n",
    "好的，下一节我们将讲解 LangChain 的记忆（memory）能力。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
